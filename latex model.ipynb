{
 "metadata": {
  "name": "",
  "signature": "sha256:b51b67a8c0c44fb9dc6edcba10686023a4b234bab034aac06ec21006a695cef7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from time import time\n",
      "import ast\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "from sklearn.metrics import jaccard_similarity_score\n",
      "from sklearn.metrics import hamming_loss\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import f1_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LatexFeatureExtractor():\n",
      "    def __init__(self, tag_df, num_tokens):\n",
      "        \n",
      "        print 'Initializing LatexFeatureExtractor object with top %d tokens...' % (num_tokens)\n",
      "        \n",
      "        self.tag_df = tag_df\n",
      "        self.num_keywords = tag_df.shape[0]\n",
      "        \n",
      "        t0 = time()\n",
      "        \n",
      "        keywords = tag_df['keyword'].values.tolist()\n",
      "        self.keywords = { k:keywords.index(k) for k in keywords}\n",
      "        \n",
      "        latex_token_set = self.top_n_latex_set( keywords, num_tokens )\n",
      "        self.latex_token_set = { t : latex_token_set.index(t) for t in latex_token_set}\n",
      "        self.num_features = len(latex_token_set)\n",
      "        \n",
      "        print 'Initialization complete. Time: %f' % (time()-t0)\n",
      "        \n",
      "    \n",
      "    def top_latex_tokens(self, keyword):\n",
      "        \"\"\"\n",
      "        This function accepts a keyword and returns a pandas dataframe of the\n",
      "        LaTeX tokens extracted for questions containing that keyword sorted\n",
      "        by the number of times the tokens occur across all questions\n",
      "        @params\n",
      "            - keyword: python string for particular keyword\n",
      "        \"\"\"\n",
      "        # Get index of row containing keyword\n",
      "        index = self.tag_df[ self.tag_df['keyword'] == keyword].index[0]\n",
      "\n",
      "        # Extract LaTeX tokens and counts\n",
      "        latex_dict = ast.literal_eval( self.tag_df.iloc[index]['latex_tokens'] )\n",
      "\n",
      "        # Put information in pandas DataFrame for quick sorting\n",
      "        tokens = latex_dict.keys()\n",
      "        count = []\n",
      "        for token in tokens:\n",
      "            count.append( latex_dict[token] )\n",
      "\n",
      "        token_df = pd.DataFrame({'token' : tokens, 'count' :  count})\n",
      "        token_df = token_df.sort('count', ascending=False)\n",
      "\n",
      "        return token_df\n",
      "    \n",
      "    \n",
      "    def top_n_latex_tokens( self, keyword, n ):  \n",
      "        \"\"\"\n",
      "        This function returns the top n LaTeX tokens associated with a particular tag\n",
      "        @params\n",
      "            - keyword: python string of particular keyword\n",
      "            - n: number of LaTeX tokens to return\n",
      "        \"\"\"\n",
      "        latex_tokens = self.top_latex_tokens(keyword)\n",
      "        top_n_tokens = latex_tokens.head(n)\n",
      "        \n",
      "        return top_n_tokens['token'].values.tolist()\n",
      "    \n",
      "\n",
      "    def top_n_latex_set( self, keywords, num_tokens):\n",
      "        \"\"\"\n",
      "        This function extracts the set of top LaTeX tokens across all keyword arguments\n",
      "        @params\n",
      "            - keywords: python list of keywords\n",
      "            - num_tokens: upper bound on number of LaTeX tokens to extract from each keyword\n",
      "        \"\"\"\n",
      "        set_token_features = []\n",
      "\n",
      "        for kw in keywords:\n",
      "            kw_tokens = self.top_n_latex_tokens(kw, num_tokens)\n",
      "            set_token_features = set_token_features + kw_tokens\n",
      "            set_token_features = list(set(set_token_features))\n",
      "\n",
      "        return set_token_features\n",
      "    \n",
      "    \n",
      "    def label_features(self, keywords):\n",
      "        \"\"\"\n",
      "        Convert list of keyword strings to list of keyword indices\n",
      "        @params\n",
      "            - keywords: python list of keyword strings\n",
      "        \"\"\"\n",
      "        features = []\n",
      "        \n",
      "        for keyword in keywords:\n",
      "            if keyword in self.keywords:\n",
      "                index = self.keywords[keyword]\n",
      "                features.append(index)\n",
      "        \n",
      "        return features\n",
      "    \n",
      "    \n",
      "    def binarize_keywords(self, indices):\n",
      "        \"\"\"\n",
      "        Given a list of keyword indices, returns numpy array of \n",
      "        binarized features where binarized[i] == 1 if i in indices.\n",
      "        \"\"\"\n",
      "        binarized = [0 for i in range(self.num_keywords)]\n",
      "\n",
      "        for i in indices:\n",
      "            binarized[i] = 1\n",
      "\n",
      "        return binarized\n",
      "    \n",
      "    \n",
      "    def binarize_latex(self, indices):\n",
      "        \"\"\"\n",
      "        Given a list of keyword indices, returns numpy array of \n",
      "        binarized features where binarized[i] == 1 if i in indices.\n",
      "        \"\"\"\n",
      "        binarized = [0 for i in range(self.num_features)]\n",
      "\n",
      "        for i in indices:\n",
      "            binarized[i] = 1\n",
      "\n",
      "        return binarized\n",
      "\n",
      "    \n",
      "    def remove_latex_symbols(self, list_of_latex):\n",
      "        \"\"\"\n",
      "        Given a list of strings of LaTeX expressions, this function returns the list with the\n",
      "        strings in remove_expressions removed from the expressions\n",
      "        \"\"\"\n",
      "        remove_expressions = [\"\\\\(\", \"\\\\)\", \"\\(\", \"\\)\", \"\\\\[\", \"\\\\]\"]\n",
      "        latex_expressions = []\n",
      "\n",
      "        for latex in list_of_latex:\n",
      "            for remove_exp in remove_expressions:\n",
      "                if remove_exp in latex:\n",
      "                    latex = latex.replace(remove_exp, '')\n",
      "            latex_expressions.append(latex)\n",
      "\n",
      "        return latex_expressions\n",
      "    \n",
      "    \n",
      "    def tokenize_latex( self, latex_expressions ):\n",
      "        \"\"\"\n",
      "        Given a list of latex_expressions, tokenize the list.\n",
      "        \"\"\"\n",
      "        latex = self.remove_latex_symbols(latex_expressions)\n",
      "        latex_tokens = ' '.join(latex).split()\n",
      "\n",
      "        return latex_tokens\n",
      "    \n",
      "    \n",
      "    def label_latex(self, latex_expressions):\n",
      "        \"\"\"\n",
      "        Given list of latex_expression, this function tokenizes the list and returns a list\n",
      "        of the indices of the tokens in the expressions from the self.latex_token_set dictionary\n",
      "        \"\"\"\n",
      "        features = []\n",
      "        tokens = self.tokenize_latex(latex_expressions)\n",
      "        \n",
      "        for token in tokens:\n",
      "            if token in self.latex_token_set:\n",
      "                features.append( self.latex_token_set[token] )\n",
      "        \n",
      "        return features\n",
      "    \n",
      "        \n",
      "    \n",
      "    def x_y_features_latex( self, x_data, y_data):\n",
      "        \"\"\"\n",
      "        Given list of input and output tags, return binary feature representation \n",
      "        suitable for input into scikit-learn classifiers\n",
      "        \"\"\"\n",
      "        if len(x_data) != len(y_data):\n",
      "            # sanity check\n",
      "            print 'len(x) != len(y)'\n",
      "            return None\n",
      "        \n",
      "        t0 = time()\n",
      "        \n",
      "        x_train = []\n",
      "        y_train = []\n",
      "        zero_count = 0\n",
      "        \n",
      "        for i in range(len(x_data)):\n",
      "            \n",
      "            x_feats = self.label_latex( x_data[i] )\n",
      "            y_feats = self.label_features( y_data[i] )\n",
      "\n",
      "            if x_feats and y_feats:\n",
      "                x_train.append( self.binarize_latex(x_feats) )\n",
      "                y_train.append( self.binarize_keywords(y_feats) )\n",
      "            else:\n",
      "                zero_count += 1\n",
      "\n",
      "        x_train = np.array(x_train)\n",
      "        y_train = np.array(y_train)\n",
      "        \n",
      "        t1 = time()\n",
      "        \n",
      "        return (x_train, y_train, zero_count, t1-t0)\n",
      "    \n",
      "    \n",
      "    \n",
      "    def x_y_features_text_latex( self, x_data, y_data):\n",
      "        \"\"\"\n",
      "        Given list of keywords and LaTeX expressions found in text and corresponding \n",
      "        keyword labels per question, return binary feature representations of x features\n",
      "        and y labels suitable for input into scikit-learn classifiers\n",
      "        @params\n",
      "            - x_data: python list of lists of keywords and LaTeX expressions\n",
      "                x_data[0] : python list of keywords found in question text\n",
      "                x_data[1] : python list of LaTeX expressions found in question text\n",
      "            - y_data: python list of strings of keyword labels\n",
      "        \"\"\"\n",
      "        if len(x_data) != len(y_data):\n",
      "            # sanity check\n",
      "            print 'len(x) != len(y)'\n",
      "            return None\n",
      "        \n",
      "        t0 = time()\n",
      "        \n",
      "        x_train = []\n",
      "        y_train = []\n",
      "        zero_count = 0\n",
      "        \n",
      "        for i in range(len(x_data)):\n",
      "            \n",
      "            # Get the keyword features and LaTeX token features\n",
      "            keyword_feats = self.label_features( x_data[i][0] ) \n",
      "            keyword_feats = self.binarize_keywords( keyword_feats )\n",
      "            \n",
      "            latex_feats = self.label_latex( x_data[i][1] )\n",
      "            latex_feats = self.binarize_latex( latex_feats )\n",
      "            \n",
      "            # Combine both features\n",
      "            x_feats = keyword_feats + latex_feats\n",
      "            y_feats = self.label_features( y_data[i] )\n",
      "\n",
      "            if x_feats:\n",
      "                x_train.append( x_feats )\n",
      "                y_train.append( self.binarize_keywords(y_feats) )\n",
      "            else:\n",
      "                zero_count += 1\n",
      "\n",
      "        x_train = np.array(x_train)\n",
      "        y_train = np.array(y_train)\n",
      "        \n",
      "        t1 = time()\n",
      "        \n",
      "        return (x_train, y_train, zero_count, t1-t0)\n",
      "    \n",
      "    \n",
      "    def y_true(self, y_data):\n",
      "        \"\"\"\n",
      "        Given list of output tags, return binary feature representation \n",
      "        suitable for input into scikit-learn classifier predictors.\n",
      "        \"\"\"\n",
      "        t0 = time()\n",
      "\n",
      "        y_true = []\n",
      "        zero_count = 0\n",
      "        \n",
      "        for i in range(len(y_data)):\n",
      "            y_feats = self.label_features(y_data[i])\n",
      "\n",
      "            if y_feats:\n",
      "                y_true.append( self.binarize_keywords(y_feats) )\n",
      "            else:\n",
      "                zero_count += 1\n",
      "\n",
      "        y_true = np.array(y_true)\n",
      "        \n",
      "        t1 = time()\n",
      "        \n",
      "        return (y_true, zero_count, t1-t0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "question_info = pd.read_csv('/home/vagrant/datacourse/MathQuestionTagging/data/question_info_data_2.csv', index_col=0)\n",
      "tag_info = pd.read_csv('/home/vagrant/datacourse/MathQuestionTagging/data/tag_info_data_2.csv', index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split data into training and test set\n",
      "train, test = train_test_split(question_info, test_size = 0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert string representation to list of string keywords\n",
      "\n",
      "# LaTeX embedded within  train questions\n",
      "x_train_raw = []\n",
      "# Train question keywords\n",
      "y_train_raw = []\n",
      "\n",
      "# LaTeX embedded within test questions\n",
      "x_test_raw = []\n",
      "# Test question keywords\n",
      "y_test_raw = []\n",
      "\n",
      "for i in range( train.shape[0] ):\n",
      "    x_train_raw.append( [ast.literal_eval(train[i][4]), ast.literal_eval(train[i][1])] )\n",
      "    y_train_raw.append( ast.literal_eval(train[i][0]) )\n",
      "\n",
      "for i in range( test.shape[0]):\n",
      "    x_test_raw.append( [ast.literal_eval(test[i][4]), ast.literal_eval(test[i][1])] )\n",
      "    y_test_raw.append( ast.literal_eval(test[i][0]) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train_raw[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[['parallel', 'radius', 'circle', 'point'],\n",
        " ['\\\\( \\\\int_C (-$ad z\\\\vec i + $ad y\\\\vec j + $bd x\\\\vec k)\\\\cdot d\\\\vec{r} \\\\)',\n",
        "  '\\\\( C \\\\)',\n",
        "  '\\\\( $r \\\\)',\n",
        "  '\\\\( xz \\\\)',\n",
        "  '\\\\( y \\\\)',\n",
        "  '\\\\(y\\\\)',\n",
        "  '\\\\( \\\\int_C (-$ad z\\\\vec i + $ad y\\\\vec j + $bd x\\\\vec k)\\\\cdot d\\\\vec{r} = \\\\)']]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### Testing\n",
      "\n",
      "x_train_test = x_train_raw[:1000]\n",
      "y_train_test = y_train_raw[:1000]\n",
      "\n",
      "x_test_test = x_test_raw[:100]\n",
      "y_test_test = y_test_raw[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### LaTeX only Testing\n",
      "\n",
      "for i in range(len(x_train_test)):\n",
      "    x_train_test[i] = x_train_test[i][1]\n",
      "    \n",
      "for i in range(len(x_test_test)):\n",
      "    x_test_test[i] = x_test_test[i][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lfe = LatexFeatureExtractor(tag_info, 5)\n",
      "\n",
      "x_train_T, y_train_T, aa, bb = lfe.x_y_features_latex(x_train_test, y_train_test)\n",
      "x_test_T, y_test_T, aa, bb = lfe.x_y_features_latex(x_test_test, y_test_test )\n",
      "\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train_T, y_train_T)\n",
      "\n",
      "y_pred = clf_LinearSVC.predict( x_test_T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initializing LatexFeatureExtractor object with top 5 tokens...\n",
        "Initialization complete. Time: 8.979958"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train_T, y_train_T, aa, bb = lfe.x_y_features_text_latex(x_train_test, y_train_test)\n",
      "x_test_T, y_test_T, aa, bb = lfe.x_y_features_text_latex(x_test_test, y_test_test )\n",
      "\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train_T, y_train_T)\n",
      "y_pred = clf_LinearSVC.predict( x_test_T )\n",
      "\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_test_T, y_pred)\n",
      "#### Done test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Jaccard: 0.133107 \n"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing keywords & LaTeX features together\n",
      "n = 5\n",
      "lfe = LatexFeatureExtractor(tag_info, n)\n",
      "\n",
      "x_train, y_train, train_zero, train_feat_time = lfe.x_y_features_text_latex(x_train_raw, y_train_raw)\n",
      "x_test, y_true, test_zero, test_feat_time = lfe.x_y_features_text_latex(x_test_raw, y_test_raw)\n",
      "\n",
      "print 'Training set feature extraction time: %f ' % train_feat_time\n",
      "print 'Test set feature extraction time: %f ' % test_feat_time\n",
      "\n",
      "t0 = time()\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train, y_train)\n",
      "t1 = time()\n",
      "\n",
      "t2 = time()\n",
      "y_pred = clf_LinearSVC.predict( x_test )\n",
      "t3 = time()\n",
      "\n",
      "model_time = t1-t0\n",
      "predict_time = t3-t2\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initializing LatexFeatureExtractor object with top 5 tokens...\n",
        "Initialization complete. Time: 8.061275"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training set feature extraction time: 17.107172 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test set feature extraction time: 3.869844 \n",
        "Model training time: 970.284956 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Prediction time: 166.239523 \n",
        "Jaccard: 0.370155 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001006 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.639475 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.395026 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.488369 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing keywords & LaTeX features together\n",
      "n = 10\n",
      "lfe = LatexFeatureExtractor(tag_info, n)\n",
      "\n",
      "x_train, y_train, train_zero, train_feat_time = lfe.x_y_features_text_latex(x_train_raw, y_train_raw)\n",
      "x_test, y_true, test_zero, test_feat_time = lfe.x_y_features_text_latex(x_test_raw, y_test_raw)\n",
      "\n",
      "print 'Training set feature extraction time: %f ' % train_feat_time\n",
      "print 'Test set feature extraction time: %f ' % test_feat_time\n",
      "\n",
      "t0 = time()\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train, y_train)\n",
      "t1 = time()\n",
      "\n",
      "t2 = time()\n",
      "y_pred = clf_LinearSVC.predict( x_test )\n",
      "t3 = time()\n",
      "\n",
      "model_time = t1-t0\n",
      "predict_time = t3-t2\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initializing LatexFeatureExtractor object with top 10 tokens...\n",
        "Initialization complete. Time: 8.839814"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training set feature extraction time: 21.669490 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test set feature extraction time: 4.900098 \n",
        "Model training time: 1303.382721 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Prediction time: 227.412290 \n",
        "Jaccard: 0.381413 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001001 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.638044 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.408346 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.497984 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing keywords & LaTeX features together\n",
      "n = 20\n",
      "lfe = LatexFeatureExtractor(tag_info, n)\n",
      "\n",
      "x_train, y_train, train_zero, train_feat_time = lfe.x_y_features_text_latex(x_train_raw, y_train_raw)\n",
      "x_test, y_true, test_zero, test_feat_time = lfe.x_y_features_text_latex(x_test_raw, y_test_raw)\n",
      "\n",
      "print 'Training set feature extraction time: %f ' % train_feat_time\n",
      "print 'Test set feature extraction time: %f ' % test_feat_time\n",
      "\n",
      "t0 = time()\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train, y_train)\n",
      "t1 = time()\n",
      "\n",
      "t2 = time()\n",
      "y_pred = clf_LinearSVC.predict( x_test )\n",
      "t3 = time()\n",
      "\n",
      "model_time = t1-t0\n",
      "predict_time = t3-t2\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initializing LatexFeatureExtractor object with top 20 tokens...\n",
        "Initialization complete. Time: 10.833837"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training set feature extraction time: 31.171797 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test set feature extraction time: 9.079602 \n",
        "Model training time: 1983.923705 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Prediction time: 346.825713 \n",
        "Jaccard: 0.394018 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.000988 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.641939 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.423156 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.510077 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Only LaTeX\n",
      "n = 30\n",
      "lfe = LatexFeatureExtractor(tag_info, n)\n",
      "\n",
      "x_train, y_train, train_zero, train_feat_time = lfe.x_y_train_latex_only(x_train_raw, y_train_raw)\n",
      "x_test, y_true, test_zero, test_feat_time = lfe.x_y_train_latex_only(x_test_raw, y_test_raw)\n",
      "\n",
      "print 'Training set feature extraction time: %f ' % train_feat_time\n",
      "print 'Test set feature extraction time: %f ' % test_feat_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initializing LatexFeatureExtractor object with top 30 tokens...\n",
        "Initialization complete. Time: 9.523920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = time()\n",
      "clf_LinearSVC = OneVsRestClassifier(LinearSVC()).fit(x_train, y_train)\n",
      "t1 = time()\n",
      "\n",
      "t2 = time()\n",
      "y_pred = clf_LinearSVC.predict( x_test )\n",
      "t3 = time()\n",
      "\n",
      "model_time = t1-t0\n",
      "predict_time = t3-t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 5 LaTeX symbols\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model training time: 319.014556 \n",
        "Jaccard: 0.167364 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001161 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.614099 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.171601 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.268245 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 10 LaTeX symbols\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model training time: 601.102666 \n",
        "Prediction time: 97.537741 \n",
        "Jaccard: 0.210099 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001148 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.600309 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.218178 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.320040 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 20 LaTeX symbols\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model training time: 1026.710583 \n",
        "Prediction time: 178.027727 \n",
        "Jaccard: 0.243493 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001135 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.597612 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.256290 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.358735 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top 30 LaTeX symbols\n",
      "\n",
      "print 'Model training time: %f ' % model_time\n",
      "print 'Prediction time: %f ' % predict_time\n",
      "print 'Jaccard: %f ' % jaccard_similarity_score(y_true, y_pred)\n",
      "print 'Hamming loss: %f ' % hamming_loss(y_true, y_pred)\n",
      "print 'Precision: %f ' % precision_score(y_true, y_pred, average='micro')  \n",
      "print 'Recall: %f ' % recall_score(y_true, y_pred, average='micro')\n",
      "print 'F1 score: %f ' % f1_score(y_true, y_pred, average='micro')  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model training time: 1438.764691 \n",
        "Prediction time: 248.952480 \n",
        "Jaccard: 0.262690 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hamming loss: 0.001124 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Precision: 0.599038 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall: 0.276582 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 score: 0.378436 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 201
    }
   ],
   "metadata": {}
  }
 ]
}